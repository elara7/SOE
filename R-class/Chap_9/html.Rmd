---
title: "Regression"
author: "Elara"
date: "2016年5月4日"
output:
  pdf_document: 
      latex_engine: xelatex
      includes:
            in_header: header.tex
  html_document:
    number_sections: yes
    theme: cerulean
  word_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 线性回归       

## 线性模型
$$Y_i=e^{\beta_1+\beta_2X_i+\epsilon_i}$$      
$$Y_i=\frac{1}{e^{\beta_1+\beta_2X_i+\epsilon_i}}$$    
$$Y_i=\beta_1+(0.75-\beta_1)e^{-\beta_2(X_i-2)}+\epsilon_i$$       
$$Y_i=\beta_1+\beta_2^{3}X_i+\epsilon_i$$         
$$Y_i=\beta_1+\beta_2(\frac{1}{X_i})+\epsilon_i$$   


1. 125是线性模型 
2. 没有截距项的时候R2不能用。此时OLS的FOC没有$\beta_0$相关，得不到残差和=0    
3. 无法把方差分解成可解释和不可解释部分。        
4. 即使截距项不显著也不能去掉。去掉的话一定过原点。      
5. R2受到模型变量数目影响。要用adj.R2    

##LM线性模型估计OLS
```{r }
#Y X 线性
options(digits=3)
fit <- lm(weight ~ height, data = women)
summary(fit)

coefficients(fit)

fitted(fit)

residuals(fit)

deviance(fit)
#置信区间0.99
confint(fit,level=0.99)

plot(women$height,women$weight,main="Women Age 30-39",xlab="Height",ylab="Weight")

abline(fit)
```

```{r}
#x和y非线性
fit2 <- lm(weight ~ height + I(height^2), data=women)
summary(fit2)
plot(women$height, women$weight, main = "Women Age 30-39",
xlab = "Height", ylab = "Weight")
lines(women$height, fitted(fit2))

```

```{r}
Anscombe<-data.frame(
X =c(10.0, 8.0, 13.0, 9.0, 11.0, 14.0, 6.0, 4.0, 12.0, 7.0, 5.0),
Y1=c(8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68),
Y2=c(9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74),
Y3=c(7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.44, 5.73),
X4=c(rep(8,7), 19, rep(8,3)),
Y4=c(6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89)
)
summary(lm(Y1~X, data=Anscombe))
summary(lm(Y2~X, data=Anscombe))
summary(lm(Y3~X, data=Anscombe))
summary(lm(Y4~X4,data=Anscombe))
head(Anscombe)
attach(Anscombe)
par(mfrow = c(2,2))
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y"); points(X,Y1); abline(lm(Y1~X))
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y"); points(X,Y2); abline(lm(Y2~X))
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y"); points(X,Y3); abline(lm(Y3~X))
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y"); points(X4,Y4); abline(lm(Y4~X4))
```

系数都是3和0.5并且都显著。可是作图结果形状完全不一致2是曲线3有异常值4除了一个点以外都是同一个竖线上

```{r}
#1没有问题
par(mfrow = c(1,1))
#2是个曲线，加入平方拟合
X2<-X^2
#存放用平方拟合的系数
lm2.sol<-lm(Y2~X+X2)
summary(lm2.sol)
#作图用x
x<-seq(min(X), max(X), by=0.1)
#作图用系数
b<-coef(lm2.sol)
y<-b[1]+b[2]*x+b[3]*x^2
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y")
#plot原图
points(X,Y2)
lines(x,y)
#3
#去掉第三个（异常值）
i<-1:11; Y31<-Y3[i!=3]; X3<-X[i!=3]
lm3.sol<-lm(Y31~X3)
summary(lm3.sol)
plot(c(3,20), c(3,13), type="n", xlab = "X", ylab = "Y")
points(X,Y3)
abline(lm3.sol)
detach(Anscombe)
```

## 异常值检测

1.diffits指标

$$DFFITS=\frac{\hat{y_i}-\hat{y_{i(i)}}}{s_(i)\sqrt{h_{ii}}}\sqrt{h_{ii}/(1-h_{ii})}$$

h是帽子矩阵，y尖=hy

```{r}
attach(Anscombe)
p<-1; n<-length(X);d<-dffits(lm(Y3~X, data=Anscombe))
cf<-1:n; cf[d>2*sqrt((p+1)/n)]
#取出1到n里面满足dffits大于2根号（（p+1）/n）
detach(Anscombe)
```

返回了异常值位置3

2.Cook's distance

$$D_i=\frac{(\hat{\beta}-\hat{\beta}^{(-i)})^{T}(X^{T}X)(\hat{\beta}-\hat{\beta}^{(-i)})}{(1+p)s^{2}}$$


```{r}
Fit<-lm(Y3~X, data=Anscombe)
cooks.distance(Fit)
par(mfrow=c(2,1))
#散点图
plot(cooks.distance(Fit),main="Cook's distance",cex=0.5)
#线图，红线表示警戒线
Np<-length(coefficients(Fit))-1#变量数
N<-length(fitted(Fit))
#红线算法
CutLevel<-4/(N-Np-1)
plot(Fit,which=4)
abline(CutLevel,0,lty=2,col="red")
```

summary

```{r}
#可以直接算dffit和cook，有问题的会带星号
influence.measures(lm(Y3~X, data=Anscombe))
```


## 最大似然估计
The following function is called a likelihood function, denoted by LF($\beta_1$; $\beta_2$; $\sigma^{2}$)
$$
LF(\beta_1,\beta_2,\sigma^{2})=f(Y_1,Y_2,\dots,Y_n|\beta_1+\beta_2X_i,\sigma^{2})=\frac{1}{\sigma^{n}(\sqrt{2\pi})^{n}}exp(\frac{1}{2}\sum \frac{(Y_i-\beta_1-\beta_2X_i)^{2}}{\sigma^{2}})
$$      
where $\beta_1$; $\beta_2$; $\sigma^{2}$ are not known. The method of maximum likelihood, as the name indicates, consists in estimating the unknown parameters in such a manner that the probability of observing the given Y’s is as high (or maximum) as possible. Therefore, we have to find the maximum of the function 6. For differentiation it is easier to express 6 in the log term as follows:   
$$
ln LF = -nln\sigma -\frac{n}{2}ln(2\pi)-\frac{1}{2}\sum \frac{(Y_i-\beta_1-\beta_2X_i)^{2}}{\sigma^{2}} \\
= -\frac{n}{2}ln\sigma^{2} -\frac{n}{2}ln(2\pi)-\frac{1}{2}\sum \frac{(Y_i-\beta_1-\beta_2X_i)^{2}}{\sigma^{2}}
$$
Differentiating 7 partially with respect to $\beta_1$; $\beta_2$, and $\sigma^{2}$, we can obtain the ML estimators.         

```
install.packages(maxLik)
```     

```{r}
library("maxLik")
indfood<-read.csv(file="C:\\Users\\44180\\Documents\\sourcetree\\elara7\\soe\\Rmarkdown\\Chap_9\\Indfood.csv")
#抽取数据
foodexp<-indfood[,1]
totalexp<-indfood[,2]
#OLS回归
lm_r <- lm(foodexp~totalexp)
summary(lm_r)
#最大似然估计
#对数似然函数
loglik=function (para){
N=length(foodexp)#样本量
e=foodexp-para[1]-para[2]*totalexp#残差项表达式，para是参数估计量
ll=-0.5*N*log(2*pi)-0.5*N*log(para[3]^2)-0.5*sum(e^2/para[3]^2)#对数似然函数，注意有个参数3
return(ll)
}
#需要1，log后的似然函数，初始值
mle1=maxLik(loglik,start=c(0.1,1,1))#3个参数，β1 β2，方差
coef(mle1)

```

## 多元线性回归

OLS是线性无偏中方差最小的。如果有一个有偏估计方差很小也可以用

```{r}
class(mtcars)
mtcar <- as.data.frame(mtcars[,c("mpg", "cyl",
"disp", "hp", "wt")])
cor(mtcar)
library(car)
scatterplotMatrix(mtcar, spread=FALSE, main="Scatter Plot Matrix")
fit3 <- lm(mpg ~ hp + wt + hp:wt, data = mtcar)
summary(fit3)
fit <- lm(weight ~ height, data=women)
par(mfrow=c(2,2))
plot(fit)

```

残差图如果是左右开口的喇叭状很可能有异方差

第四图：高杠杆有离群点，强影响(红实线是警戒线)

```{r}
#加入平方项回归
fit2 <- lm(weight ~ height + I(height^2), data=women)
plot(fit2)
```

## 系数之间相关影响实验
In order to explain the meaning of coefficients ,we have the following step.    
Regression model:       
$$y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+u_i$$ 
Step 1: 
$$w_i=y_i-\hat{\alpha}_0-\hat{\alpha}_1x_{i2}$$ 
Step 2: 
$$v_i=x_{i1}-\hat{b}_0-\hat{b}_1x_{i2}$$        
Step 3: 
$$\bar{\beta}_1=\frac{\sum v_iw_i}{\sum v_i^{2}}$$      

```{r}
mtcar <- as.data.frame(mtcars[,c("mpg", "cyl", "disp", "hp", "wt")])
fit <- lm(mpg~wt+disp, data=mtcar)
summary(fit)
fit1 <- lm(mpg~disp, data=mtcar)
fit2 <- lm(wt~disp, data=mtcar)
fit3 <- lm(fit1$residuals~fit2$residuals-1)#没常数项用-1
summary(fit3)
```

说明x2对x1系数没有影响

## 置信区间
```{r}
mtcar <- as.data.frame(mtcars[,c("mpg", "cyl", "disp", "hp", "wt")])
mtcarn<-mtcar[order(mtcar$wt),]
fit <- lm(mpg~wt, data=mtcarn)
conf=predict(fit,interval="confidence",level=0.95)
conf
plot(mpg~wt, data=mtcarn)
abline(fit)
lines(mtcarn$wt,conf[,2],lty=3,col="blue")
lines(mtcarn$wt,conf[,3],lty=3,col="blue")
```

## 假设检验

```{r }
mtcar <- as.data.frame(mtcars[,c("mpg", "cyl",
"disp", "hp", "wt")])
library(car)
fit <- lm(mpg ~ hp + wt, data = mtcar)
summary(fit)
```

```{r}
linearHypothesis(fit, "hp = 0")#变量hp的系数=0

linearHypothesis(fit, "hp = -0.5")

linearHypothesis(fit, "hp - wt= 0")#hp和wt相等
```

F检验的f值，总是对应假设中T检验t值的平方（要在相同原假设下采用正确形式）



